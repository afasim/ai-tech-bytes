name: Daily AI Tech Bytes Video Generation

on:
  schedule:
    - cron: '0 8 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      use_rss:
        description: 'Use RSS feeds for news'
        required: false
        default: 'true'
      use_api:
        description: 'Use NewsAPI for news'
        required: false
        default: 'true'

jobs:
  generate-video:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.11']
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip' # This caches your Python libraries
      
      # --- THIS IS THE NEW STEP YOU NEED TO ADD ---
      - name: Cache HuggingFace Models
        uses: actions/cache@v4
        with:
          # This is the default directory where transformers downloads models
          path: ~/.cache/huggingface/hub
          # The key identifies the cache. We include requirements.txt
          # so if you change transformers version, it creates a new cache.
          key: ${{ runner.os }}-huggingface-cache-v1-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-huggingface-cache-v1-
      # --- END OF NEW STEP ---
            
      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg imagemagick
      
      - name: Create .env file
        env:
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        run: |
          echo "NEWS_API_KEY=$NEWS_API_KEY" > newsapi.env
          echo "API_KEY=$NEWS_API_KEY" > newsapikey.env.txt
      
      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Generate Daily Video
        env:
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}
        run: |
          python main.py \
            --use-enhanced \
            --use-summarization
        continue-on-error: false
      
      - name: Upload Artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: daily-video-output
          path: |
            output/
            data/today_news.json
            data/asset_manifest_*.json
          retention-days: 30
      
      - name: Commit Generated Files
        if: success()
        run: |
          git config --global user.email "automation@github.com"
          git config --global user.name "GitHub Actions"
          
          # Add generated files
          git add -A output/ data/today_news.json data/ai_news_audio.mp3 data/ai_news_audio_script.txt 2>/dev/null || true
          
          # Check if there are changes
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: auto-generated daily video $(date +%Y-%m-%d)"
            git push origin main || echo "Push failed, may need rebasing"
          fi
      
      - name: Prepare Upload Summary
        if: always()
        run: |
          echo "## Daily Video Generation Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Date: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- Status: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          
          if [ -f data/today_news.json ]; then
            echo "- Articles Processed: $(jq length data/today_news.json)" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f output/ai_tech_bytes_youtube_shorts.mp4 ]; then
            echo "- Video Generated: YouTube Shorts (1080x1920)" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f output/ai_tech_bytes_youtube.mp4 ]; then
            echo "- Video Generated: YouTube Standard (1920x1080)" >> $GITHUB_STEP_SUMMARY
          fi

  validate-video:
    runs-on: ubuntu-latest
    needs: generate-video
    if: always()
    
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: daily-video-output
      
      - name: Validate Video Files
        run: |
          echo "Checking generated videos..."
          if [ -f output/ai_tech_bytes_youtube_shorts.mp4 ]; then
            echo "✓ YouTube Shorts video found"
          else
            echo "✗ YouTube Shorts video missing"
          fi
          
          if [ -f output/ai_tech_bytes_youtube.mp4 ]; then
            echo "✓ YouTube Standard video found"
          else
            echo "✗ YouTube Standard video missing"
          fi
          
          if [ -f data/today_news.json ]; then
            echo "✓ News data found"
          else
            echo "✗ News data missing"
          fi

  # Optional: Cloud upload steps (uncomment and configure)
  # upload-to-cloud:
  #   runs-on: ubuntu-latest
  #   needs: validate-video
  #   if: success()
  #   
  #   steps:
  #     - name: Download Artifacts
  #       uses: actions/download-artifact@v4
  #       with:
  #         name: daily-video-output
  #     
  #     # Example: Upload to Google Cloud Storage
  #     - name: Setup Google Cloud
  #       uses: google-github-actions/setup-gcloud@v1
  #       with:
  #         service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
  #     
  #     - name: Upload to GCS
  #       run: |
  #         gsutil -m cp -r output/* gs://your-bucket-name/daily-videos/$(date +%Y-%m-%d)/
